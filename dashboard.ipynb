{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2bddce2",
   "metadata": {},
   "source": [
    "# Apex Weld Quality â€“ Phase 1 Dashboard\n",
    "## Data Preparation, Feature Engineering & Analysis\n",
    "\n",
    "This notebook is the **interactive analysis dashboard** for Phase 1 of the Apex weld-quality project. It:\n",
    "\n",
    "1. Ingests and validates all weld-run data (sensor CSVs + images + labels)\n",
    "2. Explores dataset statistics, label distributions, and signal quality\n",
    "3. Engineers features from sensor time-series and image statistics\n",
    "4. Creates a reproducible, group-based train/val/test split (no leakage)\n",
    "5. Builds PyTorch datasets ready for downstream modelling\n",
    "6. Exports all artefacts and a data-card summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86adf88",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Standard libraries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import sys, os, json, logging, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: interactive plots\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    HAS_PLOTLY = True\n",
    "except ImportError:\n",
    "    HAS_PLOTLY = False\n",
    "    print(\"plotly not installed â€“ falling back to matplotlib only\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# â”€â”€ Project modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ensure project root is on sys.path\n",
    "PROJECT_ROOT = Path().resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import (\n",
    "    DATA_DIR, LABELS_CSV, SPLIT_DIR, OUTPUT_DIR, DASHBOARD_DIR,\n",
    "    LABEL_COL, SAMPLE_ID_COL, LABEL_MAP, LABEL_INV,\n",
    "    SENSOR_COLUMNS, FIXED_SEQ_LEN, IMAGE_SIZE,\n",
    "    TRAIN_RATIO, VAL_RATIO, TEST_RATIO, RANDOM_SEED,\n",
    ")\n",
    "from src.data_ingestion import ingest\n",
    "from src.feature_engineering import (\n",
    "    build_feature_table, extract_sensor_features,\n",
    "    extract_image_features, sensor_to_fixed_tensor,\n",
    ")\n",
    "from src.splitter import group_split, save_split, load_split\n",
    "from src.dataset import WeldDataset, compute_normalize_stats\n",
    "\n",
    "# â”€â”€ Logging & style â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
    "plt.rcParams.update({\"figure.dpi\": 110, \"savefig.dpi\": 150, \"figure.figsize\": (12, 5)})\n",
    "\n",
    "print(\"All imports OK âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bde5fa",
   "metadata": {},
   "source": [
    "## 2. Define Project Constants and Paths\n",
    "\n",
    "All configuration is centralised in `src/config.py`. We print the key values here for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_info = {\n",
    "    \"DATA_DIR\": str(DATA_DIR),\n",
    "    \"LABELS_CSV\": str(LABELS_CSV),\n",
    "    \"SPLIT_DIR\": str(SPLIT_DIR),\n",
    "    \"OUTPUT_DIR\": str(OUTPUT_DIR),\n",
    "    \"SENSOR_COLUMNS\": SENSOR_COLUMNS,\n",
    "    \"FIXED_SEQ_LEN\": FIXED_SEQ_LEN,\n",
    "    \"IMAGE_SIZE\": IMAGE_SIZE,\n",
    "    \"SPLIT_RATIOS\": f\"train={TRAIN_RATIO}, val={VAL_RATIO}, test={TEST_RATIO}\",\n",
    "    \"RANDOM_SEED\": RANDOM_SEED,\n",
    "    \"LABEL_MAP\": LABEL_MAP,\n",
    "}\n",
    "for k, v in config_info.items():\n",
    "    print(f\"  {k:20s} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078b842",
   "metadata": {},
   "source": [
    "## 3. Data Ingestion â€“ Discover and Load All Weld Runs\n",
    "\n",
    "Each weld run lives in its own folder (e.g. `08-17-22-0011-00/`) containing:\n",
    "- A sensor CSV with columns: Date, Time, Part No, Pressure, CO2 Weld Flow, Feed, Primary Weld Current, Wire Consumed, Secondary Weld Voltage, Remarks\n",
    "- An `images/` sub-folder with inspection photographs\n",
    "\n",
    "The `ingest()` function discovers all runs, validates each CSV, catalogues images, and merges labels from `labels.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ingestion pipeline\n",
    "manifest, sensor_data = ingest(DATA_DIR, LABELS_CSV)\n",
    "\n",
    "print(f\"Runs discovered : {len(manifest)}\")\n",
    "print(f\"Labelled        : {manifest[LABEL_COL].notna().sum()}\")\n",
    "print(f\"Sensor data keys: {len(sensor_data)}\")\n",
    "print()\n",
    "\n",
    "# Show manifest\n",
    "display(manifest.drop(columns=[\"image_paths\"], errors=\"ignore\").head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec80674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample raw sensor DataFrame for one run\n",
    "sample_run = list(sensor_data.keys())[0]\n",
    "print(f\"Sample run: {sample_run}  ({len(sensor_data[sample_run])} rows)\")\n",
    "display(sensor_data[sample_run].head(10))\n",
    "print(f\"\\nDtypes:\\n{sensor_data[sample_run].dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52252383",
   "metadata": {},
   "source": [
    "## 4. Data Validation â€“ Identify Missing, Corrupt, and Mismatched Records\n",
    "\n",
    "We check for: empty CSVs, NaN values in sensor channels, zero-variance columns, missing images, and duration outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build validation report\n",
    "val_rows = []\n",
    "for _, row in manifest.iterrows():\n",
    "    sid = row[SAMPLE_ID_COL]\n",
    "    sdf = sensor_data[sid]\n",
    "    nan_counts = sdf[SENSOR_COLUMNS].isnull().sum().to_dict()\n",
    "    val_rows.append({\n",
    "        \"sample_id\": sid,\n",
    "        \"n_rows\": row[\"n_sensor_rows\"],\n",
    "        \"duration_s\": row[\"duration_s\"],\n",
    "        \"n_images\": row[\"n_images\"],\n",
    "        \"const_cols\": row[\"const_sensor_cols\"],\n",
    "        \"issues\": row[\"issues\"],\n",
    "        **{f\"nan_{c}\": nan_counts[c] for c in SENSOR_COLUMNS},\n",
    "    })\n",
    "\n",
    "validation_df = pd.DataFrame(val_rows)\n",
    "\n",
    "# Flag runs with issues\n",
    "print(\"=== Data Validation Report ===\\n\")\n",
    "n_issues = validation_df[\"issues\"].apply(len).sum()\n",
    "print(f\"Total runs with issues: {(validation_df['issues'].apply(len) > 0).sum()} / {len(validation_df)}\")\n",
    "\n",
    "# Duration outlier detection (IQR)\n",
    "durations = validation_df[\"duration_s\"].dropna()\n",
    "Q1, Q3 = durations.quantile(0.25), durations.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "low, high = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "outlier_mask = (durations < low) | (durations > high)\n",
    "if outlier_mask.any():\n",
    "    print(f\"\\nDuration outliers (outside [{low:.1f}, {high:.1f}]s):\")\n",
    "    display(validation_df.loc[outlier_mask, [\"sample_id\", \"duration_s\"]])\n",
    "else:\n",
    "    print(f\"No duration outliers (IQR range [{low:.1f}, {high:.1f}]s)\")\n",
    "\n",
    "# Show full table\n",
    "display(validation_df.style.applymap(\n",
    "    lambda v: \"background-color: #ffcccc\" if isinstance(v, list) and len(v) > 0 else \"\",\n",
    "    subset=[\"issues\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5800ee6",
   "metadata": {},
   "source": [
    "## 5. Define the Unit of Prediction and Align Labels\n",
    "\n",
    "**Decision:** One sample = one complete weld run (Part No). Each run folder maps to exactly one row in `labels.csv`. The label is binary: `0 = good`, `1 = defect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f884efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify label alignment\n",
    "print(\"Label map:\", LABEL_MAP)\n",
    "print()\n",
    "\n",
    "label_check = manifest[[SAMPLE_ID_COL, LABEL_COL]].copy()\n",
    "label_check[\"label_name\"] = label_check[LABEL_COL].map(LABEL_MAP)\n",
    "label_check[\"has_sensor_data\"] = label_check[SAMPLE_ID_COL].isin(sensor_data.keys())\n",
    "\n",
    "n_labelled = label_check[LABEL_COL].notna().sum()\n",
    "n_unlabelled = label_check[LABEL_COL].isna().sum()\n",
    "print(f\"Labelled runs   : {n_labelled}\")\n",
    "print(f\"Unlabelled runs : {n_unlabelled}\")\n",
    "\n",
    "if n_unlabelled > 0:\n",
    "    print(\"âš  Unlabelled runs (will be excluded from supervised training):\")\n",
    "    display(label_check[label_check[LABEL_COL].isna()])\n",
    "\n",
    "display(label_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669464c",
   "metadata": {},
   "source": [
    "## 6. Exploratory Dataset Overview Dashboard\n",
    "\n",
    "Summary statistics across all weld runs: durations, row counts, runs-per-date, and per-sensor aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "fig.suptitle(\"Dataset Overview Dashboard\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "# (a) Weld duration histogram\n",
    "ax = axes[0, 0]\n",
    "durations = manifest[\"duration_s\"].dropna()\n",
    "ax.hist(durations, bins=15, color=\"steelblue\", edgecolor=\"white\")\n",
    "ax.set_xlabel(\"Duration (s)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Weld Duration Distribution\")\n",
    "ax.axvline(durations.mean(), color=\"red\", ls=\"--\", label=f\"mean={durations.mean():.1f}s\")\n",
    "ax.legend()\n",
    "\n",
    "# (b) Rows per run\n",
    "ax = axes[0, 1]\n",
    "rows_per_run = manifest[\"n_sensor_rows\"]\n",
    "ax.hist(rows_per_run, bins=15, color=\"darkorange\", edgecolor=\"white\")\n",
    "ax.set_xlabel(\"Sensor Rows\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Sensor Readings per Run\")\n",
    "ax.axvline(rows_per_run.mean(), color=\"red\", ls=\"--\", label=f\"mean={rows_per_run.mean():.0f}\")\n",
    "ax.legend()\n",
    "\n",
    "# (c) Runs per date\n",
    "ax = axes[1, 0]\n",
    "manifest[\"_date\"] = manifest[SAMPLE_ID_COL].str[:8]\n",
    "date_counts = manifest[\"_date\"].value_counts().sort_index()\n",
    "ax.bar(date_counts.index, date_counts.values, color=\"mediumseagreen\", edgecolor=\"white\")\n",
    "ax.set_xlabel(\"Date group\")\n",
    "ax.set_ylabel(\"# Runs\")\n",
    "ax.set_title(\"Runs per Date\")\n",
    "ax.tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "# (d) Summary stats table (as text)\n",
    "ax = axes[1, 1]\n",
    "ax.axis(\"off\")\n",
    "all_sensor = pd.concat([sensor_data[sid][SENSOR_COLUMNS] for sid in sensor_data], ignore_index=True)\n",
    "stats = all_sensor.describe().T[[\"mean\", \"std\", \"min\", \"max\"]].round(2)\n",
    "tbl = ax.table(\n",
    "    cellText=stats.values,\n",
    "    rowLabels=stats.index,\n",
    "    colLabels=stats.columns,\n",
    "    loc=\"center\",\n",
    "    cellLoc=\"center\",\n",
    ")\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(9)\n",
    "tbl.scale(1.2, 1.4)\n",
    "ax.set_title(\"Global Sensor Statistics\", fontsize=12, pad=20)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "DASHBOARD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(DASHBOARD_DIR / \"01_dataset_overview.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved â†’ {DASHBOARD_DIR / '01_dataset_overview.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8e9a0",
   "metadata": {},
   "source": [
    "## 7. Label Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea488f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = manifest[manifest[LABEL_COL].notna()].copy()\n",
    "labelled[\"label_name\"] = labelled[LABEL_COL].map(LABEL_MAP)\n",
    "\n",
    "if len(labelled) > 0:\n",
    "    vc = labelled[\"label_name\"].value_counts()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "    \n",
    "    # Bar chart\n",
    "    colors = [\"#4CAF50\" if x == \"good\" else \"#F44336\" for x in vc.index]\n",
    "    axes[0].bar(vc.index, vc.values, color=colors, edgecolor=\"white\", width=0.5)\n",
    "    for i, (lbl, cnt) in enumerate(vc.items()):\n",
    "        axes[0].text(i, cnt + 0.1, str(cnt), ha=\"center\", fontweight=\"bold\")\n",
    "    axes[0].set_title(\"Label Counts (bar)\")\n",
    "    axes[0].set_ylabel(\"# Runs\")\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(vc.values, labels=vc.index, autopct=\"%1.0f%%\", colors=colors,\n",
    "                startangle=90, textprops={\"fontsize\": 12})\n",
    "    axes[1].set_title(\"Label Proportions\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(DASHBOARD_DIR / \"02_label_distribution.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Class imbalance warning\n",
    "    majority = vc.max()\n",
    "    minority = vc.min()\n",
    "    ratio = majority / minority if minority > 0 else float(\"inf\")\n",
    "    print(f\"\\nClass imbalance ratio: {ratio:.1f}:1  (majority={vc.idxmax()}, minority={vc.idxmin()})\")\n",
    "    if ratio > 3:\n",
    "        print(\"âš  Significant imbalance detected. Consider:\")\n",
    "        print(\"  â€¢ Weighted loss function (class_weight in BCE / CrossEntropy)\")\n",
    "        print(\"  â€¢ Oversampling minority class (SMOTE, random duplication)\")\n",
    "        print(\"  â€¢ Stratified sampling in DataLoader\")\n",
    "    else:\n",
    "        print(\"âœ“ Imbalance within acceptable range.\")\n",
    "else:\n",
    "    print(\"No labels available â€“ skipping distribution analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e89494",
   "metadata": {},
   "source": [
    "## 8. Sensor Signal Visualization â€“ Representative Examples\n",
    "\n",
    "Multi-panel plots of all 6 sensor channels for selected weld runs with weld-phase annotations (idle â†’ arc ignition â†’ steady state â†’ ramp-down â†’ cool-down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469fdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select representative runs: first good, first defect, and one from a different date\n",
    "example_ids = []\n",
    "if len(labelled) > 0:\n",
    "    good_ids = labelled[labelled[LABEL_COL] == 0][SAMPLE_ID_COL].tolist()\n",
    "    defect_ids = labelled[labelled[LABEL_COL] == 1][SAMPLE_ID_COL].tolist()\n",
    "    if good_ids:\n",
    "        example_ids.append(good_ids[0])\n",
    "    if defect_ids:\n",
    "        example_ids.append(defect_ids[0])\n",
    "    # Add one from a different date if available\n",
    "    all_ids = manifest[SAMPLE_ID_COL].tolist()\n",
    "    for sid in all_ids:\n",
    "        if sid not in example_ids and sid[:8] != example_ids[0][:8]:\n",
    "            example_ids.append(sid)\n",
    "            break\n",
    "else:\n",
    "    example_ids = list(sensor_data.keys())[:3]\n",
    "\n",
    "print(f\"Plotting {len(example_ids)} representative runs: {example_ids}\\n\")\n",
    "\n",
    "for sid in example_ids:\n",
    "    sdf = sensor_data[sid].copy()\n",
    "    \n",
    "    # Get label name\n",
    "    lbl_row = manifest[manifest[SAMPLE_ID_COL] == sid]\n",
    "    lbl_val = lbl_row[LABEL_COL].values[0] if len(lbl_row) else None\n",
    "    lbl_name = LABEL_MAP.get(lbl_val, \"unlabelled\") if pd.notna(lbl_val) else \"unlabelled\"\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 10), sharex=True)\n",
    "    fig.suptitle(f\"Run: {sid}  |  Label: {lbl_name}\", fontsize=14, fontweight=\"bold\")\n",
    "    \n",
    "    # Time axis (seconds from start)\n",
    "    if \"datetime\" in sdf.columns and sdf[\"datetime\"].notna().any():\n",
    "        t = (sdf[\"datetime\"] - sdf[\"datetime\"].min()).dt.total_seconds().values\n",
    "    else:\n",
    "        t = np.arange(len(sdf)) * 0.11  # ~110ms intervals\n",
    "    \n",
    "    for i, col in enumerate(SENSOR_COLUMNS):\n",
    "        ax = axes[i // 2, i % 2]\n",
    "        ax.plot(t, sdf[col].values, linewidth=0.8)\n",
    "        ax.set_ylabel(col, fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Annotate weld phases on Primary Weld Current panel\n",
    "    current = sdf[\"Primary Weld Current\"].values\n",
    "    threshold = 10.0\n",
    "    arc_on = np.where(current > threshold)[0]\n",
    "    if len(arc_on) > 0:\n",
    "        t_start = t[arc_on[0]]\n",
    "        t_end = t[arc_on[-1]]\n",
    "        for ax_row in axes:\n",
    "            for ax in ax_row:\n",
    "                ax.axvspan(0, t_start, alpha=0.08, color=\"blue\", label=\"idle\")\n",
    "                ax.axvspan(t_start, t_start + 3, alpha=0.12, color=\"orange\", label=\"ignition\")\n",
    "                ax.axvspan(t_end - 1, t_end, alpha=0.12, color=\"purple\", label=\"ramp-down\")\n",
    "                ax.axvspan(t_end, t[-1], alpha=0.08, color=\"gray\", label=\"cool-down\")\n",
    "    \n",
    "    axes[-1, 0].set_xlabel(\"Time (s)\")\n",
    "    axes[-1, 1].set_xlabel(\"Time (s)\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    fig.savefig(DASHBOARD_DIR / f\"03_signals_{sid}.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9489c2b",
   "metadata": {},
   "source": [
    "## 9. Data Quality Indicators â€“ Outliers, Noise, and Class Imbalance\n",
    "\n",
    "Per-run boxplots of sensor summary stats, outlier detection (IQR), and signal-to-noise ratio during steady-state welding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-run summary stats for boxplot analysis\n",
    "run_stats = []\n",
    "for sid, sdf in sensor_data.items():\n",
    "    row = {\"sample_id\": sid}\n",
    "    for col in SENSOR_COLUMNS:\n",
    "        vals = sdf[col].dropna()\n",
    "        row[f\"{col}__mean\"] = vals.mean()\n",
    "        row[f\"{col}__max\"] = vals.max()\n",
    "        row[f\"{col}__std\"] = vals.std()\n",
    "    # SNR during arcing phase\n",
    "    current = sdf[\"Primary Weld Current\"].values\n",
    "    arcing = current > 10.0\n",
    "    if arcing.sum() > 5:\n",
    "        arc_current = current[arcing]\n",
    "        row[\"arc_current_snr\"] = arc_current.mean() / arc_current.std() if arc_current.std() > 0 else np.inf\n",
    "        arc_voltage = sdf[\"Secondary Weld Voltage\"].values[arcing]\n",
    "        row[\"arc_voltage_snr\"] = arc_voltage.mean() / arc_voltage.std() if np.std(arc_voltage) > 0 else np.inf\n",
    "    else:\n",
    "        row[\"arc_current_snr\"] = 0.0\n",
    "        row[\"arc_voltage_snr\"] = 0.0\n",
    "    run_stats.append(row)\n",
    "\n",
    "run_stats_df = pd.DataFrame(run_stats).set_index(\"sample_id\")\n",
    "\n",
    "# Boxplots of per-run sensor means and maxes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "fig.suptitle(\"Per-Run Sensor Statistics â€“ Boxplots\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "for i, col in enumerate(SENSOR_COLUMNS):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    data_to_plot = [\n",
    "        run_stats_df[f\"{col}__mean\"].dropna().values,\n",
    "        run_stats_df[f\"{col}__max\"].dropna().values,\n",
    "        run_stats_df[f\"{col}__std\"].dropna().values,\n",
    "    ]\n",
    "    bp = ax.boxplot(data_to_plot, labels=[\"mean\", \"max\", \"std\"], patch_artist=True)\n",
    "    for patch, color in zip(bp[\"boxes\"], [\"#2196F3\", \"#FF9800\", \"#4CAF50\"]):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "    ax.set_title(col, fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "fig.savefig(DASHBOARD_DIR / \"04_sensor_boxplots.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# SNR summary\n",
    "print(\"\\n=== Signal-to-Noise Ratio (arcing phase) ===\")\n",
    "print(f\"  Primary Weld Current   SNR: mean={run_stats_df['arc_current_snr'].mean():.2f}\")\n",
    "print(f\"  Secondary Weld Voltage SNR: mean={run_stats_df['arc_voltage_snr'].mean():.2f}\")\n",
    "\n",
    "# IQR outlier counts per column\n",
    "print(\"\\n=== Outlier Runs per Sensor (IQR method) ===\")\n",
    "for col in SENSOR_COLUMNS:\n",
    "    means = run_stats_df[f\"{col}__mean\"].dropna()\n",
    "    Q1, Q3 = means.quantile(0.25), means.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((means < Q1 - 1.5*IQR) | (means > Q3 + 1.5*IQR)).sum()\n",
    "    print(f\"  {col:30s}: {outliers} outlier runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea2df1",
   "metadata": {},
   "source": [
    "## 10. Preprocessing and Standardization â€“ Resampling, Normalization, Padding\n",
    "\n",
    "Each run's sensor time-series is padded/truncated to `FIXED_SEQ_LEN` rows. Normalization stats (mean, std per channel) are computed from the **training set only** to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate fixed-length tensor conversion and normalization\n",
    "\n",
    "# First, compute median sampling interval\n",
    "intervals = []\n",
    "for sid, sdf in sensor_data.items():\n",
    "    if \"datetime\" in sdf.columns and sdf[\"datetime\"].notna().sum() > 1:\n",
    "        dt = sdf[\"datetime\"].diff().dt.total_seconds().dropna()\n",
    "        intervals.extend(dt.values.tolist())\n",
    "median_interval = np.median(intervals) if intervals else 0.11\n",
    "print(f\"Median sampling interval: {median_interval*1000:.1f} ms\")\n",
    "print(f\"Fixed sequence length: {FIXED_SEQ_LEN} rows\")\n",
    "\n",
    "# Convert one example to fixed tensor (before normalization)\n",
    "demo_sid = list(sensor_data.keys())[0]\n",
    "raw_tensor = sensor_to_fixed_tensor(sensor_data[demo_sid], FIXED_SEQ_LEN)\n",
    "print(f\"\\nRaw tensor shape: {raw_tensor.shape}  (seq_len Ã— n_channels)\")\n",
    "print(f\"Before normalization â€“ channel means: {raw_tensor.mean(axis=0).round(2)}\")\n",
    "print(f\"Before normalization â€“ channel stds:  {raw_tensor.std(axis=0).round(2)}\")\n",
    "\n",
    "# We'll compute norm stats from the split in next sections â€“ preview here\n",
    "train_ids = list(sensor_data.keys())[:6]  # stand-in for actual train split\n",
    "norm_stats_preview = compute_normalize_stats(sensor_data, train_ids)\n",
    "print(f\"\\nNormalization stats (from {len(train_ids)} train runs):\")\n",
    "print(f\"  mean: {np.round(norm_stats_preview['mean'], 3)}\")\n",
    "print(f\"  std:  {np.round(norm_stats_preview['std'], 3)}\")\n",
    "\n",
    "# Apply normalization\n",
    "mu, sd = norm_stats_preview[\"mean\"], norm_stats_preview[\"std\"].copy()\n",
    "sd[sd == 0] = 1.0\n",
    "normed = (raw_tensor - mu) / sd\n",
    "\n",
    "# Before / after plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].plot(raw_tensor[:, 3], label=\"Primary Weld Current (raw)\")\n",
    "axes[0].set_title(f\"Before Normalization â€“ {demo_sid}\")\n",
    "axes[0].set_xlabel(\"Time step\")\n",
    "axes[0].legend()\n",
    "axes[1].plot(normed[:, 3], label=\"Primary Weld Current (z-scored)\", color=\"darkorange\")\n",
    "axes[1].set_title(f\"After Z-Score Normalization\")\n",
    "axes[1].set_xlabel(\"Time step\")\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(DASHBOARD_DIR / \"05_normalization_demo.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f6961",
   "metadata": {},
   "source": [
    "## 11. Feature Engineering â€“ Sensor Statistics and Derived Signals\n",
    "\n",
    "Using `build_feature_table()` we extract per-run features: global stats (mean, std, min, max, range, IQR), windowed volatility, rate-of-change, and weld-phase timing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c756bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the full feature table\n",
    "feature_df = build_feature_table(manifest, sensor_data)\n",
    "\n",
    "print(f\"Feature table shape: {feature_df.shape[0]} samples Ã— {feature_df.shape[1]} features\\n\")\n",
    "print(\"Feature categories:\")\n",
    "\n",
    "# Categorize features\n",
    "cats = {}\n",
    "for col in feature_df.columns:\n",
    "    prefix = col.split(\"__\")[0] if \"__\" in col else col\n",
    "    cats.setdefault(prefix, []).append(col)\n",
    "\n",
    "for cat, cols in cats.items():\n",
    "    print(f\"  {cat:35s}: {len(cols)} features\")\n",
    "\n",
    "print(f\"\\nSample features for {feature_df.index[0]}:\")\n",
    "display(feature_df.iloc[:3].T.round(3))\n",
    "\n",
    "# Feature mapping table\n",
    "print(\"\\n=== Raw Input â†’ Engineered Feature Mapping ===\")\n",
    "mapping = [\n",
    "    (\"Sensor CSV\", \"Global stats\", \"mean, std, min, max, median, range, IQR per channel\"),\n",
    "    (\"Sensor CSV\", \"Windowed stats\", \"sliding-window mean-of-std, std-of-mean, max-std\"),\n",
    "    (\"Sensor CSV\", \"Rate of change\", \"diff mean, std, max, min per channel\"),\n",
    "    (\"Sensor CSV\", \"Weld phases\", \"arc fraction, start/end idx, duration fraction\"),\n",
    "    (\"Images/\", \"Image brightness\", \"mean, std, min, max of pixel intensity (grayscale)\"),\n",
    "    (\"Images/\", \"Image texture\", \"histogram entropy, edge density (Sobel gradient)\"),\n",
    "]\n",
    "mapping_df = pd.DataFrame(mapping, columns=[\"Raw Source\", \"Feature Group\", \"Description\"])\n",
    "display(mapping_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e48493",
   "metadata": {},
   "source": [
    "## 12. Feature Correlation and Importance Analysis\n",
    "\n",
    "Pearson correlation heatmap, highly-correlated feature pairs, and point-biserial correlation with binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbca530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Correlation heatmap ---\n",
    "# Select numeric columns only, drop any with zero variance\n",
    "numeric_feats = feature_df.select_dtypes(include=[np.number])\n",
    "nonconst = numeric_feats.loc[:, numeric_feats.std() > 0]\n",
    "\n",
    "corr = nonconst.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "sns.heatmap(\n",
    "    corr, ax=ax, cmap=\"RdBu_r\", center=0, vmin=-1, vmax=1,\n",
    "    xticklabels=False, yticklabels=True,\n",
    "    linewidths=0.1, cbar_kws={\"shrink\": 0.6},\n",
    ")\n",
    "ax.set_title(\"Feature Correlation Matrix\", fontsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=6)\n",
    "plt.tight_layout()\n",
    "fig.savefig(DASHBOARD_DIR / \"06_correlation_heatmap.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Highly correlated pairs (|r| > 0.95)\n",
    "high_corr = []\n",
    "for i in range(len(corr)):\n",
    "    for j in range(i + 1, len(corr)):\n",
    "        if abs(corr.iloc[i, j]) > 0.95:\n",
    "            high_corr.append((corr.index[i], corr.columns[j], round(corr.iloc[i, j], 3)))\n",
    "\n",
    "print(f\"\\nHighly correlated pairs (|r| > 0.95): {len(high_corr)}\")\n",
    "if high_corr:\n",
    "    hc_df = pd.DataFrame(high_corr, columns=[\"Feature A\", \"Feature B\", \"r\"])\n",
    "    display(hc_df.head(20))\n",
    "else:\n",
    "    print(\"  None found.\")\n",
    "\n",
    "# Point-biserial correlation with label\n",
    "if manifest[LABEL_COL].notna().sum() > 2:\n",
    "    from scipy.stats import pointbiserialr\n",
    "    \n",
    "    labelled_ids = manifest[manifest[LABEL_COL].notna()][SAMPLE_ID_COL].tolist()\n",
    "    feat_labelled = nonconst.loc[nonconst.index.isin(labelled_ids)]\n",
    "    labels_arr = manifest.set_index(SAMPLE_ID_COL).loc[feat_labelled.index, LABEL_COL].values.astype(float)\n",
    "    \n",
    "    pb_corrs = {}\n",
    "    for col in feat_labelled.columns:\n",
    "        vals = feat_labelled[col].values\n",
    "        if np.std(vals) > 0:\n",
    "            r, p = pointbiserialr(labels_arr, vals)\n",
    "            pb_corrs[col] = abs(r)\n",
    "    \n",
    "    pb_series = pd.Series(pb_corrs).sort_values(ascending=False)\n",
    "    \n",
    "    # Top 20 features by label correlation\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    top_n = min(20, len(pb_series))\n",
    "    top = pb_series.head(top_n)\n",
    "    ax.barh(range(top_n), top.values, color=\"steelblue\")\n",
    "    ax.set_yticks(range(top_n))\n",
    "    ax.set_yticklabels(top.index, fontsize=8)\n",
    "    ax.set_xlabel(\"|Point-Biserial r|\")\n",
    "    ax.set_title(f\"Top {top_n} Features by Label Correlation\")\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(DASHBOARD_DIR / \"07_feature_importance.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nMost discriminative signals:\")\n",
    "    for feat, r in top.head(5).items():\n",
    "        base = feat.split(\"__\")[0]\n",
    "        print(f\"  {feat:45s}  |r|={r:.3f}  (derived from {base})\")\n",
    "else:\n",
    "    print(\"Insufficient labels for point-biserial correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd48a13d",
   "metadata": {},
   "source": [
    "## 13. Create Reproducible Group-Based Train/Val/Test Split\n",
    "\n",
    "Grouping by date prefix so runs from the same session stay in the same split (prevents temporal leakage). Fixed seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform group-based split\n",
    "split_map = group_split(manifest)\n",
    "split_path = save_split(split_map)\n",
    "\n",
    "print(f\"Split saved to: {split_path}\\n\")\n",
    "print(\"Split summary:\")\n",
    "for k, ids in split_map.items():\n",
    "    print(f\"  {k:5s}: {len(ids)} runs â†’ {ids}\")\n",
    "\n",
    "# Verify no overlap\n",
    "all_ids_flat = []\n",
    "for ids in split_map.values():\n",
    "    all_ids_flat.extend(ids)\n",
    "assert len(all_ids_flat) == len(set(all_ids_flat)), \"ERROR: Overlap between splits!\"\n",
    "print(\"\\nâœ“ No overlap between train/val/test sets.\")\n",
    "\n",
    "# Label distribution within each split\n",
    "if manifest[LABEL_COL].notna().sum() > 0:\n",
    "    print(\"\\nLabel distribution per split:\")\n",
    "    lbl_lookup = manifest.set_index(SAMPLE_ID_COL)[LABEL_COL]\n",
    "    split_label_summary = []\n",
    "    for split_name, ids in split_map.items():\n",
    "        labels = lbl_lookup.loc[ids].dropna()\n",
    "        n_good = (labels == 0).sum()\n",
    "        n_defect = (labels == 1).sum()\n",
    "        n_unlabelled = len(ids) - len(labels)\n",
    "        split_label_summary.append({\n",
    "            \"split\": split_name, \"n_runs\": len(ids),\n",
    "            \"good\": n_good, \"defect\": n_defect, \"unlabelled\": n_unlabelled,\n",
    "        })\n",
    "    display(pd.DataFrame(split_label_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61e7c2",
   "metadata": {},
   "source": [
    "## 14. Build PyTorch Dataset and DataLoader Pipeline\n",
    "\n",
    "Instantiate `WeldDataset` for each split with normalization stats computed on the training set only. Verify tensor shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalization stats from TRAIN set only\n",
    "norm_stats = compute_normalize_stats(sensor_data, split_map[\"train\"])\n",
    "print(\"Normalization stats (train-only):\")\n",
    "for ch, m, s in zip(SENSOR_COLUMNS, norm_stats[\"mean\"], norm_stats[\"std\"]):\n",
    "    print(f\"  {ch:30s}  mean={m:10.3f}  std={s:10.3f}\")\n",
    "\n",
    "# Build datasets\n",
    "datasets = {}\n",
    "for split_name, ids in split_map.items():\n",
    "    ds = WeldDataset(\n",
    "        manifest=manifest,\n",
    "        sensor_data=sensor_data,\n",
    "        sample_ids=ids,\n",
    "        feature_df=feature_df,\n",
    "        normalize_stats=norm_stats,\n",
    "    )\n",
    "    datasets[split_name] = ds\n",
    "\n",
    "# Demo: access one sample\n",
    "print(\"\\n=== Sample from train set ===\")\n",
    "sample = datasets[\"train\"][0]\n",
    "for k, v in sample.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"  {k:15s}: shape={tuple(v.shape)}, dtype={v.dtype}\")\n",
    "    else:\n",
    "        print(f\"  {k:15s}: {v}\")\n",
    "\n",
    "# Create a DataLoader and iterate one batch\n",
    "train_loader = DataLoader(datasets[\"train\"], batch_size=min(4, len(datasets[\"train\"])), shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"\\n=== One batch (batch_size={batch['sensor_seq'].shape[0]}) ===\")\n",
    "print(f\"  sensor_seq : {tuple(batch['sensor_seq'].shape)}\")\n",
    "print(f\"  features   : {tuple(batch['features'].shape)}\")\n",
    "print(f\"  label      : {batch['label'].tolist()}\")\n",
    "print(f\"  sample_id  : {batch['sample_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaeb59a",
   "metadata": {},
   "source": [
    "## 15. Export Artefacts â€“ Feature Table, Manifest, Normalization Stats, Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36738489",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DASHBOARD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. Feature table\n",
    "ft_path = OUTPUT_DIR / \"feature_table.csv\"\n",
    "feature_df.to_csv(ft_path)\n",
    "print(f\"âœ“ Feature table        â†’ {ft_path}  ({ft_path.stat().st_size / 1024:.1f} KB)\")\n",
    "\n",
    "# 2. Manifest (drop non-serializable columns)\n",
    "manifest_export = manifest.drop(columns=[\"image_paths\"], errors=\"ignore\")\n",
    "manifest_path = OUTPUT_DIR / \"manifest.csv\"\n",
    "manifest_export.to_csv(manifest_path, index=False)\n",
    "print(f\"âœ“ Manifest             â†’ {manifest_path}  ({manifest_path.stat().st_size / 1024:.1f} KB)\")\n",
    "\n",
    "# 3. Normalization stats\n",
    "norm_path = OUTPUT_DIR / \"normalize_stats.json\"\n",
    "with open(norm_path, \"w\") as f:\n",
    "    json.dump({k: v.tolist() for k, v in norm_stats.items()}, f, indent=2)\n",
    "print(f\"âœ“ Normalization stats  â†’ {norm_path}\")\n",
    "\n",
    "# 4. Split definition (already saved, confirm)\n",
    "split_file = SPLIT_DIR / \"split.json\"\n",
    "print(f\"âœ“ Split definition     â†’ {split_file}\")\n",
    "\n",
    "# 5. Dashboard plots\n",
    "plot_files = sorted(DASHBOARD_DIR.glob(\"*.png\"))\n",
    "print(f\"âœ“ Dashboard plots      â†’ {len(plot_files)} PNGs in {DASHBOARD_DIR}\")\n",
    "for p in plot_files:\n",
    "    print(f\"    {p.name}  ({p.stat().st_size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab14bb",
   "metadata": {},
   "source": [
    "## 16. Generate Data Card Summary Report\n",
    "\n",
    "Programmatic one-page data card summarising dataset characteristics, preprocessing decisions, and known issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# Build data card content\n",
    "n_labelled = manifest[LABEL_COL].notna().sum()\n",
    "n_good = (manifest[LABEL_COL] == 0).sum()\n",
    "n_defect = (manifest[LABEL_COL] == 1).sum()\n",
    "dur = manifest[\"duration_s\"].dropna()\n",
    "\n",
    "data_card = f\"\"\"# Apex Weld Quality â€“ Data Card\n",
    "\n",
    "## Dataset Overview\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| Dataset name | Apex Weld Quality â€“ sampleData |\n",
    "| Date range | Aug 17â€“18, 2022 |\n",
    "| Total weld runs | {len(manifest)} |\n",
    "| Labelled runs | {n_labelled} (good={n_good}, defect={n_defect}) |\n",
    "| Sensor channels | {len(SENSOR_COLUMNS)} ({', '.join(SENSOR_COLUMNS)}) |\n",
    "| Sampling rate | ~9â€“10 Hz (median interval â‰ˆ {median_interval*1000:.0f} ms) |\n",
    "| Rows per run | {int(manifest['n_sensor_rows'].min())}â€“{int(manifest['n_sensor_rows'].max())} (mean â‰ˆ {manifest['n_sensor_rows'].mean():.0f}) |\n",
    "| Weld duration | {dur.min():.1f}â€“{dur.max():.1f} s (mean â‰ˆ {dur.mean():.1f} s) |\n",
    "| Images per run | {int(manifest['n_images'].min())}â€“{int(manifest['n_images'].max())} |\n",
    "\n",
    "## Label Definitions\n",
    "- **0 = good**: Normal weld with no identified defects\n",
    "- **1 = defect**: Weld with one or more quality issues\n",
    "\n",
    "## Preprocessing Choices\n",
    "| Choice | Value |\n",
    "|--------|-------|\n",
    "| Unit of prediction | One complete weld run (Part No) |\n",
    "| Sequence length | Fixed at {FIXED_SEQ_LEN} rows (pad with zeros / truncate) |\n",
    "| Normalization | Per-channel z-score (mean/std from train set only) |\n",
    "| Image processing | Grayscale, resized to {IMAGE_SIZE}, basic statistics extracted |\n",
    "| Split strategy | Group-by-date to prevent temporal leakage |\n",
    "| Split ratios | Train {TRAIN_RATIO:.0%} / Val {VAL_RATIO:.0%} / Test {TEST_RATIO:.0%} |\n",
    "| Random seed | {RANDOM_SEED} |\n",
    "\n",
    "## Known Issues & Assumptions\n",
    "- **Labels are placeholders**: The provided `labels.csv` contains template labels that must\n",
    "  be replaced with ground-truth annotations before training.\n",
    "- **No audio/video data**: Only sensor CSVs and still images are present in the sample data.\n",
    "  The pipeline is designed to accommodate additional modalities when available.\n",
    "- **Small dataset**: With only {len(manifest)} runs, overfitting risk is high. Consider data\n",
    "  augmentation and regularisation strategies.\n",
    "- **Remarks column**: Currently empty across all runs; reserved for operator notes.\n",
    "\n",
    "## Feature Engineering Summary\n",
    "- {feature_df.shape[1]} engineered features per run\n",
    "- Global sensor stats: mean, std, min, max, median, range, IQR\n",
    "- Windowed volatility: sliding-window std, coefficient of variation\n",
    "- Rate of change: first-difference statistics\n",
    "- Weld phase timing: arc fraction, start/end indices, duration\n",
    "- Image statistics: brightness, contrast, entropy, edge density\n",
    "\n",
    "## Files Produced\n",
    "- `outputs/feature_table.csv` â€“ Full feature matrix\n",
    "- `outputs/manifest.csv` â€“ Run manifest with validation info\n",
    "- `outputs/normalize_stats.json` â€“ Z-score parameters\n",
    "- `splits/split.json` â€“ Train/val/test split definition\n",
    "- `outputs/dashboard/` â€“ Analysis plots (PNG)\n",
    "\"\"\"\n",
    "\n",
    "# Save and render\n",
    "data_card_path = OUTPUT_DIR / \"data_card.md\"\n",
    "with open(data_card_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(data_card)\n",
    "print(f\"âœ“ Data card saved â†’ {data_card_path}\\n\")\n",
    "\n",
    "display(Markdown(data_card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24456e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Phase 1 summary report\n",
    "from main import _make_summary\n",
    "\n",
    "summary = _make_summary(manifest, feature_df, split_map)\n",
    "print(summary)\n",
    "print(\"\\n\\nðŸŽ‰ Phase 1 pipeline complete. All artefacts exported.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
